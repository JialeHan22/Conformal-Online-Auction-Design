{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53fc9faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import truncnorm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor, DMatrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import random\n",
    "from conditionalconformal import CondConf\n",
    "import itertools\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b3a6f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "\n",
    "dimension_z = 100\n",
    "dimension_x = 100\n",
    "number_z = 30\n",
    "# Generating 30 vectors, each with 100 dimensions\n",
    "z_domain = np.random.normal(size=(number_z, dimension_z))\n",
    "\n",
    "# Generating beta_1 and beta_2\n",
    "beta_1 = np.random.uniform(-1, 1, dimension_x)\n",
    "beta_2 = np.random.uniform(-1, 1, dimension_z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d394aa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_function(beta_1, beta_2):\n",
    "\n",
    "\n",
    "    def function_1(X, Z):\n",
    "        epsilon = truncnorm.rvs(-1, 1)  # Generate epsilon from a truncated normal distribution\n",
    "        T = (np.dot(beta_1.T, X) ** 2) * (np.sin(np.dot(beta_2.T, Z)) ** 2) + 1 + epsilon\n",
    "        return T\n",
    "\n",
    "    return function_1\n",
    "\n",
    "function_1 = generate_function(beta_1, beta_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bb29201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_regression(df):\n",
    "    # Extracting X and Z and converting them into suitable format for regression\n",
    "    X_data = np.array(df['X'].tolist())\n",
    "    Z_data = np.array(df['Z'].tolist())\n",
    "\n",
    "    # Concatenating X and Z\n",
    "    combined_data = np.concatenate([X_data, Z_data], axis=1)\n",
    "\n",
    "    return combined_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54325c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_fn(feature):\n",
    "    scalar_values = np.array(feature[:,dimension_x:(dimension_x+dimension_z)])#len 500\n",
    "\n",
    "    # Initialize the indicator matrix\n",
    "    matrix = np.zeros((len(np.array(feature[:,1])), number_z))\n",
    "\n",
    "    # Fill in the indicator matrix\n",
    "    for i, value in enumerate(scalar_values):\n",
    "        for j in range(0, number_z):\n",
    "            if  np.array_equal(value, z_domain[j]):\n",
    "                matrix[i, j] = 1\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8806502f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "Z_new = z_domain[np.random.randint(z_domain.shape[0])]\n",
    "\n",
    "def conformal_predict_z_0(alpha=0.1, m=100, Z_new=Z_new, N=1000, t=200):\n",
    "    IR = []\n",
    "    for j in range(t):\n",
    "        data_points = []\n",
    "        for _ in range(N):\n",
    "            # Randomly select a vector from z_domain to be Z\n",
    "            Z = z_domain[np.random.randint(z_domain.shape[0])]\n",
    "\n",
    "            # Compute the mean of the square of Z\n",
    "            mean_x = np.mean(Z**2)\n",
    "\n",
    "            # Generate a 150-dimensional vector X from a normal distribution with mean mean_x and variance 1\n",
    "            X = np.random.normal(mean_x, 1, dimension_x)\n",
    "\n",
    "            # Compute T_1 and T_2 using the generated functions\n",
    "            T_1 = function_1(X, Z)\n",
    "            #T_2 = function_2(X, Z)\n",
    "\n",
    "            # Append the data point (X, Z, T_1, T_2) to the list\n",
    "            data_points.append([X, Z, T_1])\n",
    "        # Split the data into D_cali and D_train\n",
    "        D_cali = pd.DataFrame(data_points[:N//2], columns=[\"X\", \"Z\", \"T_1\"])\n",
    "        D_train = pd.DataFrame(data_points[N//2:], columns=[\"X\", \"Z\", \"T_1\"])\n",
    "\n",
    "        # Preparing data for regression\n",
    "        X_train = prepare_data_for_regression(D_train)\n",
    "        # Extracting T_1\n",
    "        T_1_train = D_train['T_1']\n",
    "        # Using a polynomial model (Let's start with a 2nd degree polynomial)\n",
    "        poly = PolynomialFeatures(degree=2)\n",
    "        X_train_poly = poly.fit_transform(X_train)\n",
    "        # Training the model\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train_poly, T_1_train)\n",
    "\n",
    "        score_fn = lambda feature,  y : abs(y - model.predict(poly.transform(pd.DataFrame(feature))))\n",
    "        \n",
    "        condCovProgram = CondConf(score_fn, phi_fn, {})\n",
    "        condCovProgram.setup_problem(prepare_data_for_regression(D_cali),D_cali['T_1'].to_numpy())\n",
    "        \n",
    "        data_points_new = []\n",
    "        for _ in range(m):\n",
    "            # Compute the mean of the square of Z\n",
    "            mean_x_new = np.mean(Z_new**2)\n",
    "            # Generate a 150-dimensional vector X from a normal distribution with mean mean_x and variance 1\n",
    "            X_new = np.random.normal(mean_x_new, 1, dimension_x)\n",
    "            # Compute T_1 and T_2 using the generated functions\n",
    "            T_1_new = function_1(X_new, Z_new)\n",
    "            #T_2_new = function_2(X_new, Z_new)\n",
    "\n",
    "            # Append the data point (X, Z, T_1, T_2) to the list\n",
    "            data_points_new.append([X_new, Z_new, T_1_new])\n",
    "\n",
    "        # Split the data into D_cali and D_train\n",
    "        D_new = pd.DataFrame(data_points_new, columns=[\"X\", \"Z\", \"T_1\"])\n",
    "        \n",
    "        X_neww = prepare_data_for_regression(D_new)\n",
    "        T_1_new= D_new['T_1']\n",
    "        X_new_poly = poly.transform(X_neww)\n",
    "        T_1_pred_new = model.predict(X_new_poly)\n",
    "\n",
    "        Xtest = np.array([prepare_data_for_regression(D_new)[10,:]])\n",
    "        d = condCovProgram.predict(1-alpha, Xtest, lambda x, y : x) \n",
    "        \n",
    "        # Calculate intervals\n",
    "        hat_t_L = T_1_pred_new - d\n",
    "        hat_t_U = T_1_pred_new + d \n",
    "        IR.append(np.mean((hat_t_L <= T_1_new) & (T_1_new <= hat_t_U)))\n",
    "        \n",
    "\n",
    "            \n",
    "    return IR, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30e1a79e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4333.60425901413\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "Z_new = z_domain[np.random.randint(z_domain.shape[0])]\n",
    "\n",
    "IR, d = conformal_predict_z_0(alpha=0.1, m=50, Z_new=Z_new, N=10000, t=200)\n",
    "\n",
    "###\n",
    "plt.boxplot(IR, patch_artist=True, medianprops=dict(color=\"black\"), boxprops=dict(facecolor='lightblue'))\n",
    "plt.yticks( fontsize=10)\n",
    "plt.xticks([1], [''])  # Setting x-axis label to an empty string\n",
    "plt.axhline(y=0.9, color='red', linestyle='-', label='', linewidth=1)\n",
    "plt.xlabel('Random z0', fontsize=15)\n",
    "plt.ylabel('Coverage', fontsize=15)\n",
    "plt.yticks( fontsize=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7556ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "Z_new = z_domain[np.random.randint(z_domain.shape[0])]\n",
    "def conformal_predict(alpha=0.1, m=100, Z_new=Z_new, N = 1000):\n",
    "    data_points = []\n",
    "    for _ in range(N):\n",
    "        # Randomly select a vector from z_domain to be Z\n",
    "        Z = z_domain[np.random.randint(z_domain.shape[0])]\n",
    "\n",
    "        # Compute the mean of the square of Z\n",
    "        mean_x = np.mean(Z**2)\n",
    "\n",
    "        # Generate a 150-dimensional vector X from a normal distribution with mean mean_x and variance 1\n",
    "        X = np.random.normal(mean_x, 1, dimension_x)\n",
    "\n",
    "        # Compute T_1 and T_2 using the generated functions\n",
    "        T_1 = function_1(X, Z)\n",
    "        #T_2 = function_2(X, Z)\n",
    "\n",
    "        # Append the data point (X, Z, T_1, T_2) to the list\n",
    "        data_points.append([X, Z, T_1])\n",
    "    # Split the data into D_cali and D_train\n",
    "    D_cali = pd.DataFrame(data_points[:N//2], columns=[\"X\", \"Z\", \"T_1\"])\n",
    "    D_train = pd.DataFrame(data_points[N//2:], columns=[\"X\", \"Z\", \"T_1\"])\n",
    "\n",
    "    # Preparing data for regression\n",
    "    X_train = prepare_data_for_regression(D_train)\n",
    "    # Extracting T_1\n",
    "    T_1_train = D_train['T_1']\n",
    "    # Using a polynomial model (Let's start with a 2nd degree polynomial)\n",
    "    poly = PolynomialFeatures(degree=2)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    # Training the model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_poly, T_1_train)\n",
    "\n",
    "    score_fn = lambda feature,  y : abs(y - model.predict(poly.transform(pd.DataFrame(feature))))\n",
    "\n",
    "    condCovProgram = CondConf(score_fn, phi_fn, {})\n",
    "    condCovProgram.setup_problem(prepare_data_for_regression(D_cali),D_cali['T_1'].to_numpy())\n",
    "\n",
    "    data_points_new = []\n",
    "    for _ in range(m):\n",
    "        # Compute the mean of the square of Z\n",
    "        mean_x_new = np.mean(Z_new**2)\n",
    "        # Generate a 150-dimensional vector X from a normal distribution with mean mean_x and variance 1\n",
    "        X_new = np.random.normal(mean_x_new, 1, dimension_x)\n",
    "        # Compute T_1 and T_2 using the generated functions\n",
    "        T_1_new = function_1(X_new, Z_new)\n",
    "        #T_2_new = function_2(X_new, Z_new)\n",
    "\n",
    "        # Append the data point (X, Z, T_1, T_2) to the list\n",
    "        data_points_new.append([X_new, Z_new, T_1_new])\n",
    "\n",
    "    # Split the data into D_cali and D_train\n",
    "    D_new = pd.DataFrame(data_points_new, columns=[\"X\", \"Z\", \"T_1\"])\n",
    "\n",
    "    X_neww = prepare_data_for_regression(D_new)\n",
    "    T_1_new= D_new['T_1']\n",
    "    X_new_poly = poly.transform(X_neww)\n",
    "    T_1_pred_new = model.predict(X_new_poly)\n",
    "\n",
    "    Xtest = np.array([prepare_data_for_regression(D_new)[10,:]])\n",
    "    d = condCovProgram.predict(1-alpha, Xtest, lambda x, y : x) \n",
    "     \n",
    "    reserve_price = T_1_pred_new - d\n",
    "    virtual_value = np.array(T_1_new) * (np.array(T_1_new) > reserve_price)\n",
    "\n",
    "    # Find the index(es) of the maximum virtual value\n",
    "    max_virtual_value_indexes = np.where(virtual_value == np.max(virtual_value))[0]\n",
    "    winner = None\n",
    "    if len(max_virtual_value_indexes) > 1:\n",
    "    # Check the reserve price for the max virtual value indexes\n",
    "        max_reserve_price_indexes = np.where(reserve_price[max_virtual_value_indexes] == np.max(reserve_price[max_virtual_value_indexes]))[0]\n",
    "\n",
    "        if len(max_reserve_price_indexes) > 1:\n",
    "        # If multiple maximums, choose one at random\n",
    "            winner = np.random.choice(max_virtual_value_indexes[max_reserve_price_indexes])\n",
    "        else:\n",
    "        # If only one maximum\n",
    "            winner = max_virtual_value_indexes[max_reserve_price_indexes[0]]\n",
    "    else:\n",
    "    # If only one maximum virtual value\n",
    "        winner = max_virtual_value_indexes[0]\n",
    "\n",
    "    sorted_virtual_value = np.sort(virtual_value)[::-1]\n",
    "    payment = max(0, sorted_virtual_value[1], reserve_price[winner])\n",
    "    max_welfare = np.max(np.array(T_1_new))\n",
    "    \n",
    "    return payment, payment/max_welfare, payment - np.sort(np.array(T_1_new))[::-1][1], np.sort(np.array(T_1_new))[::-1][1], max_welfare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7ec75c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5848.689967870712\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "m_0 = 50\n",
    "IR_compare = []\n",
    "\n",
    "Z_new = z_domain[np.random.randint(z_domain.shape[0])]\n",
    "\n",
    "for i in range(200):\n",
    "    result = conformal_predict(alpha=0.1, m=m_0,  Z_new=Z_new, N = 10000)\n",
    "    IR_compare.append(result[2]) #IR_compare_100_100\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48364ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('Random z0', fontsize=15)\n",
    "plt.ylabel('Revenue Difference', fontsize=15)\n",
    "\n",
    "###\n",
    "plt.boxplot(IR_compare, patch_artist=True, boxprops=dict(facecolor='lightblue'),  # Box color set to blue\n",
    "            medianprops=dict(color=\"black\"))\n",
    "plt.yticks( fontsize=15.603240200456185)\n",
    "plt.xticks([1], [''])  # Setting x-axis label to an empty string\n",
    "plt.axhline(y=0, color='red', linestyle='-', label='', linewidth=1)\n",
    "plt.ylim(-5,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22ed014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conformal_predict(alpha=0.1, m=100, Z_new=Z_new):\n",
    "   \n",
    "\n",
    "    score_fn = lambda feature,  y : abs(y - model.predict(poly.transform(pd.DataFrame(feature))))\n",
    "\n",
    "    condCovProgram = CondConf(score_fn, phi_fn, {})\n",
    "    condCovProgram.setup_problem(prepare_data_for_regression(D_cali),D_cali['T_1'].to_numpy())\n",
    "\n",
    "    data_points_new = []\n",
    "    for _ in range(m):\n",
    "        # Compute the mean of the square of Z\n",
    "        mean_x_new = np.mean(Z_new**2)\n",
    "        # Generate a 150-dimensional vector X from a normal distribution with mean mean_x and variance 1\n",
    "        X_new = np.random.normal(mean_x_new, 1, dimension_x)\n",
    "        # Compute T_1 and T_2 using the generated functions\n",
    "        T_1_new = function_1(X_new, Z_new)\n",
    "        #T_2_new = function_2(X_new, Z_new)\n",
    "\n",
    "        # Append the data point (X, Z, T_1, T_2) to the list\n",
    "        data_points_new.append([X_new, Z_new, T_1_new])\n",
    "\n",
    "    # Split the data into D_cali and D_train\n",
    "    D_new = pd.DataFrame(data_points_new, columns=[\"X\", \"Z\", \"T_1\"])\n",
    "\n",
    "    X_neww = prepare_data_for_regression(D_new)\n",
    "    T_1_new= D_new['T_1']\n",
    "    X_new_poly = poly.transform(X_neww)\n",
    "    T_1_pred_new = model.predict(X_new_poly)\n",
    "\n",
    "    Xtest = np.array([prepare_data_for_regression(D_new)[10,:]])\n",
    "    d = condCovProgram.predict(1-alpha, Xtest, lambda x, y : x) \n",
    "     \n",
    "    reserve_price = T_1_pred_new - d\n",
    "    virtual_value = np.array(T_1_new) * (np.array(T_1_new) > reserve_price)\n",
    "\n",
    "    # Find the index(es) of the maximum virtual value\n",
    "    max_virtual_value_indexes = np.where(virtual_value == np.max(virtual_value))[0]\n",
    "    winner = None\n",
    "    if len(max_virtual_value_indexes) > 1:\n",
    "    # Check the reserve price for the max virtual value indexes\n",
    "        max_reserve_price_indexes = np.where(reserve_price[max_virtual_value_indexes] == np.max(reserve_price[max_virtual_value_indexes]))[0]\n",
    "\n",
    "        if len(max_reserve_price_indexes) > 1:\n",
    "        # If multiple maximums, choose one at random\n",
    "            winner = np.random.choice(max_virtual_value_indexes[max_reserve_price_indexes])\n",
    "        else:\n",
    "        # If only one maximum\n",
    "            winner = max_virtual_value_indexes[max_reserve_price_indexes[0]]\n",
    "    else:\n",
    "    # If only one maximum virtual value\n",
    "        winner = max_virtual_value_indexes[0]\n",
    "\n",
    "    sorted_virtual_value = np.sort(virtual_value)[::-1]\n",
    "    payment = max(0, sorted_virtual_value[1], reserve_price[winner])\n",
    "    max_welfare = np.max(np.array(T_1_new))\n",
    "    \n",
    "    return payment, payment/max_welfare, payment - np.sort(np.array(T_1_new))[::-1][1], np.sort(np.array(T_1_new))[::-1][1], max_welfare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72a67e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "# 设置 N 的不同值\n",
    "N_values = [1000, 3000, 5000, 7000, 9000, 11000, 13000]\n",
    "Z_new = z_domain[np.random.randint(z_domain.shape[0])]\n",
    "num_runs = 500\n",
    "\n",
    "# 初始化用于存储结果的字典\n",
    "results = {\"payment\": [], \"sb_value\": [], \"max_welfare\": []}\n",
    "\n",
    "# 对于每个 N 值，运行函数 500次并计算平均值\n",
    "for N in N_values:\n",
    "    data_points = []\n",
    "    for _ in range(N):\n",
    "        # Randomly select a vector from z_domain to be Z\n",
    "        Z = z_domain[np.random.randint(z_domain.shape[0])]\n",
    "\n",
    "        # Compute the mean of the square of Z\n",
    "        mean_x = np.mean(Z**2)\n",
    "\n",
    "        # Generate a 150-dimensional vector X from a normal distribution with mean mean_x and variance 1\n",
    "        X = np.random.normal(mean_x, 1, dimension_x)\n",
    "\n",
    "        # Compute T_1 and T_2 using the generated functions\n",
    "        T_1 = function_1(X, Z)\n",
    "        #T_2 = function_2(X, Z)\n",
    "\n",
    "        # Append the data point (X, Z, T_1, T_2) to the list\n",
    "        data_points.append([X, Z, T_1])\n",
    "    # Split the data into D_cali and D_train\n",
    "    D_cali = pd.DataFrame(data_points[:N//2], columns=[\"X\", \"Z\", \"T_1\"])\n",
    "    D_train = pd.DataFrame(data_points[N//2:], columns=[\"X\", \"Z\", \"T_1\"])\n",
    "\n",
    "    # Preparing data for regression\n",
    "    X_train = prepare_data_for_regression(D_train)\n",
    "    # Extracting T_1\n",
    "    T_1_train = D_train['T_1']\n",
    "    # Using a polynomial model (Let's start with a 2nd degree polynomial)\n",
    "    poly = PolynomialFeatures(degree=2)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    # Training the model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_poly, T_1_train)\n",
    "    \n",
    "    payments, sb_values, max_welfares = [], [], []\n",
    "    for _ in range(num_runs):\n",
    "        payment, _, _, sb_value, max_welfare = conformal_predict(0.1, 50, Z_new)\n",
    "        payments.append(payment)\n",
    "        sb_values.append(sb_value)\n",
    "        max_welfares.append(max_welfare)\n",
    "    results[\"payment\"].append(np.mean(payments))\n",
    "    results[\"sb_value\"].append(np.mean(sb_values))\n",
    "    results[\"max_welfare\"].append(np.mean(max_welfares))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8961158d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "plt.figure(figsize=(5,5))  # 修改此处以创建正方形的图形\n",
    "plt.plot(N_values[0:7], results[\"max_welfare\"][0:7], label=\"Max Welfare\", linewidth=2)  # 加粗线条\n",
    "plt.plot(N_values[0:7], results[\"payment\"][0:7], label=\"Payment\", linewidth=2)  # 加粗线条\n",
    "plt.plot(N_values[0:7], results[\"sb_value\"][0:7], label=\"2nd Best Price\", linewidth=2)  # 加粗线条\n",
    "\n",
    "\n",
    "# 设置坐标轴标签和字体大小\n",
    "plt.xlabel(\"Number of Previous Data ($N$)\", fontsize=15)\n",
    "plt.ylabel(\"Expected Values\", fontsize=15)\n",
    "\n",
    "# 设置图例和字体大小\n",
    "plt.legend(fontsize=15, bbox_to_anchor=(0.38, 0.5), loc='center left')\n",
    "\n",
    "# 设置横坐标为对数尺度，并确保刻度清晰\n",
    "#plt.xscale(\"log\")\n",
    "\n",
    "# 设置刻度标签的字体大小\n",
    "plt.xticks(N_values[0:7], labels=[str(N) for N in N_values[0:7]], fontsize=30)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1921895",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "Z_new = z_domain[np.random.randint(z_domain.shape[0])]\n",
    "data_points = []\n",
    "N = 20000\n",
    "for _ in range(N):\n",
    "    # Randomly select a vector from z_domain to be Z\n",
    "    Z = z_domain[np.random.randint(z_domain.shape[0])]\n",
    "\n",
    "    # Compute the mean of the square of Z\n",
    "    mean_x = np.mean(Z**2)\n",
    "\n",
    "    # Generate a 150-dimensional vector X from a normal distribution with mean mean_x and variance 1\n",
    "    X = np.random.normal(mean_x, 1, dimension_x)\n",
    "\n",
    "    # Compute T_1 and T_2 using the generated functions\n",
    "    T_1 = function_1(X, Z)\n",
    "    #T_2 = function_2(X, Z)\n",
    "\n",
    "    # Append the data point (X, Z, T_1, T_2) to the list\n",
    "    data_points.append([X, Z, T_1])\n",
    "# Split the data into D_cali and D_train\n",
    "D_cali = pd.DataFrame(data_points[:N//2], columns=[\"X\", \"Z\", \"T_1\"])\n",
    "D_train = pd.DataFrame(data_points[N//2:], columns=[\"X\", \"Z\", \"T_1\"])\n",
    "\n",
    "# Preparing data for regression\n",
    "X_train = prepare_data_for_regression(D_train)\n",
    "# Extracting T_1\n",
    "T_1_train = D_train['T_1']\n",
    "# Using a polynomial model (Let's start with a 2nd degree polynomial)\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "# Training the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_poly, T_1_train)\n",
    "def conformal_predict(alpha=0.1, m=100, Z_new=Z_new):\n",
    "   \n",
    "\n",
    "    score_fn = lambda feature,  y : abs(y - model.predict(poly.transform(pd.DataFrame(feature))))\n",
    "\n",
    "    condCovProgram = CondConf(score_fn, phi_fn, {})\n",
    "    condCovProgram.setup_problem(prepare_data_for_regression(D_cali),D_cali['T_1'].to_numpy())\n",
    "\n",
    "    data_points_new = []\n",
    "    for _ in range(m):\n",
    "        # Compute the mean of the square of Z\n",
    "        mean_x_new = np.mean(Z_new**2)\n",
    "        # Generate a 150-dimensional vector X from a normal distribution with mean mean_x and variance 1\n",
    "        X_new = np.random.normal(mean_x_new, 1, dimension_x)\n",
    "        # Compute T_1 and T_2 using the generated functions\n",
    "        T_1_new = function_1(X_new, Z_new)\n",
    "        #T_2_new = function_2(X_new, Z_new)\n",
    "\n",
    "        # Append the data point (X, Z, T_1, T_2) to the list\n",
    "        data_points_new.append([X_new, Z_new, T_1_new])\n",
    "\n",
    "    # Split the data into D_cali and D_train\n",
    "    D_new = pd.DataFrame(data_points_new, columns=[\"X\", \"Z\", \"T_1\"])\n",
    "\n",
    "    X_neww = prepare_data_for_regression(D_new)\n",
    "    T_1_new= D_new['T_1']\n",
    "    X_new_poly = poly.transform(X_neww)\n",
    "    T_1_pred_new = model.predict(X_new_poly)\n",
    "\n",
    "    Xtest = np.array([prepare_data_for_regression(D_new)[10,:]])\n",
    "    d = condCovProgram.predict(1-alpha, Xtest, lambda x, y : x) \n",
    "     \n",
    "    reserve_price = T_1_pred_new - d\n",
    "    virtual_value = np.array(T_1_new) * (np.array(T_1_new) > reserve_price)\n",
    "\n",
    "    # Find the index(es) of the maximum virtual value\n",
    "    max_virtual_value_indexes = np.where(virtual_value == np.max(virtual_value))[0]\n",
    "    winner = None\n",
    "    if len(max_virtual_value_indexes) > 1:\n",
    "    # Check the reserve price for the max virtual value indexes\n",
    "        max_reserve_price_indexes = np.where(reserve_price[max_virtual_value_indexes] == np.max(reserve_price[max_virtual_value_indexes]))[0]\n",
    "\n",
    "        if len(max_reserve_price_indexes) > 1:\n",
    "        # If multiple maximums, choose one at random\n",
    "            winner = np.random.choice(max_virtual_value_indexes[max_reserve_price_indexes])\n",
    "        else:\n",
    "        # If only one maximum\n",
    "            winner = max_virtual_value_indexes[max_reserve_price_indexes[0]]\n",
    "    else:\n",
    "    # If only one maximum virtual value\n",
    "        winner = max_virtual_value_indexes[0]\n",
    "\n",
    "    sorted_virtual_value = np.sort(virtual_value)[::-1]\n",
    "    payment = max(0, sorted_virtual_value[1], reserve_price[winner])\n",
    "    max_welfare = np.max(np.array(T_1_new))\n",
    "    \n",
    "    return payment, payment/max_welfare, payment - np.sort(np.array(T_1_new))[::-1][1], np.sort(np.array(T_1_new))[::-1][1], max_welfare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d449742e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 设置 m 的不同值\n",
    "m_values = list(range(50, 301, 50))\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "Z_new = z_domain[np.random.randint(z_domain.shape[0])]\n",
    "num_runs = 300\n",
    "\n",
    "# 初始化用于存储结果的字典\n",
    "results_m = {\"payment\": [], \"y_value\": [], \"max_welfare\": []}\n",
    "\n",
    "# 对于每个 m 值，运行函数 100 次并计算平均值\n",
    "for m in m_values:\n",
    "    payments, y_values, max_welfares = [], [], []\n",
    "    for _ in range(num_runs):\n",
    "        payment, _, _, y_value, max_welfare = conformal_predict(0.1, m, Z_new)\n",
    "        payments.append(payment)\n",
    "        y_values.append(y_value)\n",
    "        max_welfares.append(max_welfare)\n",
    "    results_m[\"payment\"].append(np.mean(payments))\n",
    "    results_m[\"y_value\"].append(np.mean(y_values))\n",
    "    results_m[\"max_welfare\"].append(np.mean(max_welfares))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cae3e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# 绘制结果图\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(m_values, results_m[\"max_welfare\"], label=\"Max Welfare\")\n",
    "plt.plot(m_values, results_m[\"payment\"], label=\"Payment\")\n",
    "plt.plot(m_values, results_m[\"y_value\"], label=\"2nd Best Price\")\n",
    "\n",
    "plt.xlabel(\"Number of Bidders $(m)$\", fontsize=20)\n",
    "plt.ylabel(\"Expected Values\", fontsize=30)\n",
    "plt.yticks(fontsize=25)\n",
    "plt.xticks(fontsize=25)\n",
    "plt.title(\"\")#Average Payment, 2nd Best Price, and Max Welfare for Different m Values\n",
    "# 设置图例和字体大小\n",
    "#plt.legend(fontsize=20, bbox_to_anchor=(0.0, 1), loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
